<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Aniket Agarwal</title>
  
  <meta name="author" content="Aniket Agarwal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Aniket Agarwal</name>
              </p>
              <p>I am a final year undegraduate at <a href="https://www.iitr.ac.in/">IIT Roorkee</a> majoring in Applied Mathematics.
              </p>
              <p>
                I've had the pleasure of working with <a href="https://www.etsmtl.ca/professeurs/cdesrosiers/accueil">Prof Christian Desrosiers</a> and <a href="https://josedolz.github.io/">Prof Jose Dolz</a> from ETS Montreal, on the topic of semi-supervised segmentation. I've also worked with <a href="http://www.mohamed-elhoseiny.com/">Prof Mohamed Elhoseiny</a> from KAUST, tackling the problem of long-tail Visual Relationship Recognition.
                I have worked with <a href="https://www.comp.nus.edu.sg/~ayao/">Prof Angela Yao</a> from NUS Singapore, where our problem focus was on egocentric hand action recognition.
              </p>
              <p>
                I am currently working with <a href="https://www.cs.princeton.edu/~karthikn/">Prof Karthik Narsimhan</a> on long-horizon video understanding. Also for my undergraduate thesis project, I am working with <a href="http://faculty.iitr.ac.in/~malikfma/">Prof Sanjeev Kumar</a> on the topic of Data-Driven Simulation.
                I am mostly interested in using Computer Vision for solvig interdisciplinary problems. The recent <a href="https://dellaert.github.io/NeRF/">NeRF explosion</a> is something that excites me a lot
              </p>
              <p style="text-align:center">
                <a href="mailto:aagarwal@ma.iitr.ac.in">Email</a> &nbsp/&nbsp
                <a href="data/Aniket-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=oPzYPK0AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/agarwalaniket11">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/aniket-agarwal1999">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/aniket.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/aniket.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I am interested in solving problems at the intersection of vision and graphics. Much of my research till now is on vision related problems such as Visual Relationship Recognition, 3D Hand Action Recognition, semi-supervised segmentation, etc.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>   <!-- bgcolor="#ffffd0" -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/LTVRR.jpeg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ltvrr.github.io/">
                <papertitle>Exploring Long Tail Visual Relationship Recognition with Large Vocabulary</papertitle>
              </a>
              <br>
              <strong>Aniket Agarwal*</strong>,
              <a href="https://scholar.google.com/citations?user=hBlcEY0AAAAJ">Sherif Abdelkarim*</a>,
              <a href="https://ai.stanford.edu/~optas/">Panos Achlioptas</a>, <br>
              <a href="https://scholar.google.com/citations?user=9G2OQmkAAAAJ&hl=en">Jun Chen</a>,
              <a href="https://jiaji-huang.github.io/">Jiaji Huang</a>,
              <a href="http://www.boyangli.org/">Boyang Li</a>, <br>
              <a href="http://research.baidu.com/People/index-view?id=115">Kenneth Church</a>,
              <a href="http://www.mohamed-elhoseiny.com/">Mohamed Elhoseiny</a>
              <br>
							<em>ICCV</em>, 2021
              <br>
              <a href="https://ltvrr.github.io/">project</a>
              /
              <a href="data/ltvrr.pdf">pdf</a>
              /
              <a href="data/ltvrr_supplementary_document.pdf">supp</a>
              /
              <a href="https://arxiv.org/abs/2004.00436">arXiv</a>
              /
              <a href="https://github.com/Vision-CAIR/LTVRR">code</a>
              /
              <a href="data/ltvrr.bib">cite</a>
              <p></p>
              <p>We propose new benchmarks, GQA-LT & VG8K-LT, for solving and properly targeting the problem of long-tail VRR. Additionaly, we propose RelMix and VilHub, two techniques that can be utilized on top of any VRR model to make its prediction accuracy on tail classes better.</p>
            </td>
          </tr>

          <tr>   <!-- bgcolor="#ffffd0" -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/reltransformer.jpeg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2104.11934">
                <papertitle>RelTransformer: A Transformer-Based Long-Tail Visual Relationship Recognition</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=9G2OQmkAAAAJ&hl=en">Jun Chen</a>,
              <strong>Aniket Agarwal</strong>,
              <a href="https://scholar.google.com/citations?user=hBlcEY0AAAAJ">Sherif Abdelkarim</a>, <br>
              <a href="https://scholar.google.com/citations?user=dENNKrsAAAAJ&hl=en">Deyao Zhu</a>,
              <a href="http://www.mohamed-elhoseiny.com/">Mohamed Elhoseiny</a>
              <br>
							<em>CVPR,</em> 2022
              <br>
              <a href="https://arxiv.org/abs/2104.11934">arXiv</a>
              /
              <a href="https://github.com/Vision-CAIR/RelTransformer">code</a>
              /
              <a href="data/reltransformer.bib">cite</a>
              <p></p>
              <p>Transformers have seen massive success for solving various Vision and Language related tasks. Here we propose a novel transformer based architecture for solving the long-tail VRR problem.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/scene_graph_survey.jpeg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2005.08045">
                <papertitle>Visual Relationship Detection using Scene Graphs: A Survey</papertitle>
              </a>
              <br>
              <strong>Aniket Agarwal*</strong>,
              <a href="https://ayushtues.github.io/">Ayush Mangal*</a>,
              <a href="https://www.linkedin.com/in/vipul-maharia-633b861a0">Vipul*</a>
              <br>
              <em>Survey Paper</em>
              <br>
              <a href="https://arxiv.org/abs/2005.08045">arXiv</a>
              /
              <a href="data/scene_survey.bib">cite</a>
              <p></p>
              <p>One of the first survey papers on topic of scene graphs, widely used for Visual Relationship Recognition.
              </p>
            </td>
          </tr>

          <tr>   <!-- bgcolor="#ffffd0" -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/revisiting_cycleGAN.jpeg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1908.11569">
                <papertitle>Revisiting CycleGAN for semi-supervised segmentation</papertitle>
              </a>
              <br>
              <a href="https://arnab39.github.io/">Arnab Mondal</a>,
              <strong>Aniket Agarwal</strong>,
              <a href="https://josedolz.github.io/">Jose Dolz</a>, <br>
              <a href="https://www.etsmtl.ca/professeurs/cdesrosiers/accueil">Christian Desrosiers</a>
              <br>
              <a href="https://arxiv.org/abs/1908.11569">arXiv</a>
              /
              <a href="https://github.com/arnab39/Semi-supervised-segmentation-cycleGAN">code</a>
              /
              <a href="data/revisiting.bib">cite</a>
              <p></p>
              <p>Utilizing the concepts of cycle-consistency for improving the semi-supervised baseline for image segmentation.</p>
            </td>
          </tr>

        </tbody></table>

        <!-- Education -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Education</heading>
          </td>
        </tr>
        </tbody></table>

        <table border=0 class="bg_colour" style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>

            <tr>
                <td style="padding:10px;width:25%;vertical-align:middle">
                    <div class="one">
                        <img src='images/iitr_logo.png' width="110" class="side-image">
                    </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:top">
                    <!-- <papertitle style="color:gray"><big>Software Development Engineer Intern</big> </papertitle> <papertitle ><big> | Expedia Group</big></papertitle> -->
                    <papertitle><big>Indian Institute of Technology Roorkee</big></papertitle>
                    <br>
                    <papertitle style="color:gray"><big>Integrated MSc in </big></papertitle><papertitle><big>Applied Mathematics</big></papertitle>
                    <br>
                    July '17 - May '22
                    <br>
                    <p>
                        Student Societies:
                        <ul>
                            <li>Co-President | Vision and Language Group (<a href="https://vlgiitr.github.io/">Link</a>)</li>
                            <li>Treasurer | ACM IIT Roorke Chapter (<a href="http://iitr.acm.org/#/">Link</a>)</li>
                            <li>Mentor | Student Mentorship Programme</li>
                            <li>Teaching Assistant | MAN-001 course taught to freshmen year</li>
                        </ul>
                    </p>
                </td>
            </tr>

        </tbody></table>
        </div>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Miscellaneous</heading>
              <p>
              Participated in Intern IIT 2018, held at IIT Bombay. We presented a web-based ML application, LeDoc(<a href="https://github.com/pradumangoyal/le_doc">Link</a>).
              </p>
              <p>
                Some of the best experiences I've had in my undergraduate life is due to Vision and Language Group(<a href="https://vlgiitr.github.io/">Link</a>). The seniors and people there are some of the best and loveliest you can find in IIT Roorkee. I am highly indebted for being a part of the group.
              </p>
              <p>
               In my free time, I love to watch TV shows and you can most definitely find me listening to music at any time of day. I love Rock and Lo-Fi pop genre and am an ardent fan of Radiohead.
              </p>
            </td>
          </tr>
        </tbody></table>        
        
 
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <br>
                This template is stolen from <a href="https://jonbarron.info/">here</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>

        
